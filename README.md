My research hypothesis is that for tonal language native speakers, speaking a tonal language with a larger number of lexical tones more significantly improves musical abilities, and 73 participants are recruited without payment to participate in the research by completing a questionnaire and four tasks on a webpage provided to them by me. Four tasks are designed to measure musical abilities of participants: pitch perception (10 questions), rhythm perception (10 questions), cadence learning (4 questions) and style learning (5 questions). Participants also self-reported their age, gender, language background and music background in a questionnaire before doing the tasks. The raw data spreadsheet shows each participant's background information, score for each question and their total score for each task in rows. Descriptive statistics, correlation and p-value, and linear multiple regression are used to analyze the raw data by python codes.

Analyzed data show that speakers of Chinese dialects with different numbers of lexical tones (4–9) did not differ significantly in their melody and rhythm perception as well as cadence and style learning abilities. Although the processing of pitch and melody is hypothesized to share perceptual resources with the perception of lexical tones, having different numbers of tones might not be a determinant factor. Due to each dialect having different numbers of register and contour tones, more research can be done on comparing the relative and absolute pitch perception ability of their speakers.

Participants who received music training showed advantages in music perception and cadence learning, and those who listened to music frequently showed advantages only in perception tasks. People who owned absolute pitch performed better than others only in cadence learning. However, no factor accounted for the difference in performance in style learning. Interestingly, another linguistic factor’s impact surfaced from the results: the number of foreign languages learned correlates positively with both melody and rhythm perception. Overall, these results suggest that while intra-model factors establish knowledge and enhance sensitivity toward musical stimuli, the phonological properties of languages might also influence musical perception.

## Steps to reproduce

1. I designed the background questionnaire and tasks and made the audio stimuli in Logic Pro (details see "Description of stimuli and questionnaire design", original audio wav files is in "Audio Stimuli" zip file and the logic project), rearranged their order and numbered them. Then, we developped a webpage and put the task instructions and requirement, questionnaire and audio onto the webpage in order (see related link and "code for the webpage" ).
2. Recruiting 73 participants from our social circle as well as on social media, a link to the webpage is provided to them for them to fill in their information and complete the tasks, and a csv file recording all data is automatically generated and updated as new responses are submitted. 
3. The scores of each participant is calculated manually or by using functions in excel based on this csv file.
4. Using python codes in "Data Analysis" folder, the data is analyzed using descriptive statistics, correlation and p-value, and linear multiple regression and output as csv files; graphs of correlation heatmap and regression line showing the results are generated. (Note: when reproducing, the filepath in codes needs to be changed based on where you save the raw data file)
